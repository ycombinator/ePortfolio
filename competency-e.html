<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
  <title>Tiffany A. Hrabusa: Competency E</title>
  <link href="css/style.css" type="text/css" rel="stylesheet" />
</head>
<body>
<div id="page-section">
<div id="header-section">
  <img src="images/vertical-books-messy.jpg" />
  <h1>E: design, query and evaluate information retrieval systems</h1>
</div>
<div id="nav-section">
<ul>
  <li>Introduction</li>
  <li>Philosophy</li>
  <li><a href="competency-a.html">Competency A</a></li>
  <li><a href="competency-b.html">Competency B</a></li>
  <li><a href="competency-c.html">Competency C</a></li>
  <li><a href="competency-d.html">Competency D</a></li>
  <li class="current"><a href="competency-e.html">Competency E</a></li>
  <li><a href="competency-f.html">Competency F</a></li>
  <li><a href="competency-g.html">Competency G</a></li>
  <li><a href="competency-h.html">Competency H</a></li>
  <li><a href="competency-i.html">Competency I</a></li>
  <li><a href="competency-j.html">Competency J</a></li>
  <li>Competency K</li>
  <li>Competency L</li>
  <li>Competency M</li>
  <li>Competency N</li>
  <li>Conclusion</li>
</ul>
</div>
<div id="main-section">


<h2>Introduction</h2>


<p>Part of an information professional's job is to connect users with the information they seek. To perform this duty well, I will have to understand and be able to explain information retrieval systems to assist novice patrons with their information needs. Information retrieval systems (IRSs) typically consist of two main parts: a database and a user interface. The database is the back-end structure that stores and parses the information contained in the IRS. The interface is the space where an end user connects to the database, usually through a web page or software tool, and which allows the user to provide input and receive output. Given that most library research involves at least some work in IRSs, it is imperative that I understand the principles used in the design of databases and interfaces, how to perform both simple and complex queries, and how to properly evaluate the performance of an IRS.
</p>


<h2>Evidence</h2>



<p>
The first piece of evidence I have provided is a group project for LIBR 247: Vocabulary Design. My teammates* and I chose to create a metadata schema for a photographic database intended for travel journalists. Our proposal included the creation of database fields, indexing instructions, assignment of controlled vocabularies and interface recommendations. My responsibilities for the project were to research and write the Requirements Analysis, Requirements List, and the Technical Report. Our team worked together via Elluminate to come up with the fields and vocabularies. This project became our group's masterpiece; we dedicated hundreds of hours to it and included features beyond the assignment requirements. Short of actually building the photo IRS, there is nothing I would change. Through the design of this database, I explored which attributes of the collected objects should be indexed into the database via fields. Controlled vocabularies are used in indexing to increase both the precision and recall of the database; I used my knowledge of how they work to formulate authority lists for appropriate fields, making sure to disambiguate overlapping terms. I hypothesized about the best interface to achieve maximum user efficiency for the photo database, including recommendations for the use of drop-down menus and a calendar widget. This proposal shows that I am able to design an IRS from beginning to end.
</p>

<p>
The next assignment I have listed is a database searching exercise I completed for LIBR 244: Online Searching. My task was to answer six research questions using Dialog, a proprietary database. My work in this assignment was comprehensive; I would not make any changes. As I worked through each question, I used a variety of search strategies to query the database. On Question 1, I employed a "building blocks" strategy where I chose three known concepts to search for and made sets for each. In the second part of the same question, I attempted a subject heading search. Subject headings vary by IRS, but many library-related systems use Library of Congress Subject Headings. Assuming indexing has been performed well, searching by subject headings will result in greater overall precision. In Question 4, I used the well-known "pearl-growing" strategy where a searcher finds a handful of relevant items and then browses them for additional search terms. Although these search queries were all formulated for a single IRS, I am able to translate the underlying search theory into any other IRS. 
</p>

<p>
My last piece of evidence is a database manual I wrote for LIBR 202: Information Retrieval. The manual accompanied the database I created in DBTextworks. On pages 20 through 24, I give a thorough analysis of the database's performance; if I were to rewrite this manual now, I would add more records to the database to test the precision and recall more rigorously. My evaluation was based on success or failure in three different areas: storage, retrieval and display. I determined that the storage function was well-performed because efforts were made to reduce word indexing (which creates numerous tables and can slow down searching). I also found that the database's retrieval role was affected positively by the variety of indexing used. The presence of controlled vocabularies, along with the indexing choices, resulted in extremely high rates of both precision (percent of results that are relevant) and recall (percent of relevant results retrieved). 
To evaluate the database's display, I enlisted the help of a potential user, and based on his experiences, alterations were made to the interface to include instructions on how to use special features. I learned through this assignment that database evaluation is important not just for designers, but also for users. If I am ever in a position to make collection decisions for my library, I will need to use these skills to evaluate IRSs and make certain I am choosing the best products available.</p>

<h2>Conclusion</h2>

<p>
Through the three assignments discussed above, I have shown that I am able to design, query and evaluate information retrieval systems. I understand the background principles of selecting attributes, assigning values, and employing and creating controlled vocabularies. I can use search strategies to formulate advanced queries for different IRSs. I am able to evaluate a database based on several criteria, but most especially on its precision and recall. With these strong skills in my arsenal, I will be able to explain how to use IRSs and assist patrons with using IRSs to answer their research questions.  
</p>

<p>
*Team member names are being used with permission.
</p>



<h2>Evidentiary Items</h2>



<ol>
<li><a href="evidence/Design Proposal - Metadata Schema.pdf" target="_blank">Design Proposal - Metadata Schema</a> (PDF Document)</li>


<li><a href="evidence/Database Exercise - Searching in Dialog.doc">Database Exercise - Searching in Dialog</a> (Word Document)</li>

<li><a href="evidence/Database Manual - Performance Evaluation.doc">Database Manual - Performance Evaluation</a> (Word Document, pp. 20-24)</li>
</ol>




</div>
</div>
<!--<div id="footer-section"><img class="left" src="images/vert-final.png" />  <img class="right" src="images/horiz-final.png" /></div>--></body>
</html>
